# robot.txt

> 리액트를 하다보면 public 디렉토리에 robot.txt가 있는것을 알수있습니다

---

> robots.txt는 검색로봇에게 사이트 및 웹페이지를 수집할 수 있도록 허용하거나 제한하는 국제 권고안입니다.<br /> robots.txt 파일은 항상 사이트의 루트 디렉터리에 위치해야 하며 로봇 배제 표준을 따르는 일반 텍스트 파일로 작성해야 합니다.<br /> 네이버 검색로봇은 robots.txt에 작성된 규칙을 준수하며, 만약 사이트의 루트 디렉터리에 robots.txt 파일이 없다면 모든 콘텐츠를 수집할 수 있도록 간주합니다.

```ini
[간혹 특정 목적을 위하여 개발된 웹 스크랩퍼를 포함하여 일부 불완전한 검색로봇은 robots.txt 내의 규칙을 준수하지 않을 수 있습니다.]

 그러므로 개인 정보를 포함하여 외부에 노출되면 안 되는 콘텐츠의 경우 로그인 기능을 통하여 보호하거나 다른 차단 방법을 사용해야 합니다.
```

## 위치

robot.txt는 루트 디렉터리에 위치합니다.

---

## robots.txt 규칙 예제

robots.txt 파일에 작성된 규칙은 같은 호스트, 프로토콜 및 포트 번호 하위의 페이지에 대해서만 유효합니다. http://www.example.com/robots.txt 의 내용은 http://example.com/ 와 https://example.com/ 에는 적용되지 않습니다.

대표적인 규칙은 아래와 같으며 사이트의 콘텐츠 성격에 맞게 변경해주세요.

- 다른 검색엔진의 로봇에 대하여 수집을 허용하지 않고 네이버 검색로봇만 수집 허용으로 설정합니다.

```
User-agent: *
Disallow: /
User-agent: Yeti
Allow: /
```

- 모든 검색엔진의 로봇에 대하여 수집 허용으로 설정합니다.

```
User-agent: *
Allow: /
```

- 사이트의 루트 페이지만 수집 허용으로 설정합니다.

```
User-agent: *
Disallow: /
Allow: /$
```

- 관리자 페이지, 개인 정보 페이지와 같이 검색로봇 방문을 허용하면 안 되는 웹 페이지는 수집 비허용으로 설정해주세요. 아래 예제는 네이버 검색로봇에게 /private-image, /private-video 등은 수집하면 안 된다고 알려줍니다.

```
User-agent: Yeti
Disallow: /private*/
```

- 모든 검색로봇에게 사이트의 모든 페이지에 대하여 수집을 허용하지 않는다고 알려줍니다. 이 예제는 사이트의 어떠한 페이지도 수집 대상에 포함되지 않으므로 권장하지 않습니다.

```
User-agent: *
Disallow: /
```
